# Awesome-MMLM

## ç›¸å…³æ•°æ®

| åºå· | åç§° | æ•°æ®åˆ†ç±» | è¯­è¨€ | ä¸‹è½½åœ°å€ | å‘å¸ƒæœºæ„ | ç›¸å…³é“¾æ¥ | ç®€ä»‹ |
| :-----: | :-----: | :-----: | :-----: | :-----: | :-----: | :--: | :--: |
| 1 | LLaVA-Pretrain | Pretrain | EN | [ğŸ¤—](https://huggingface.co/datasets/liuhaotian/LLaVA-Pretrain) / [ğŸ¤–](https://www.modelscope.cn/datasets/thomas/LLaVA-Pretrain/summary) | [haotian-liu](https://github.com/haotian-liu) | [HomePage](https://llava-vl.github.io) / [Paper](https://arxiv.org/abs/2310.03744) / [GitHub](https://github.com/haotian-liu/LLaVA) | LLaVA Visual Instruct Pretrain LCS-558K æ˜¯ LAION/CC/SBU æ•°æ®é›†çš„ä¸€ä¸ªå­é›†ï¼Œç»è¿‡ç­›é€‰çš„æ¦‚å¿µè¦†ç›–åˆ†å¸ƒæ›´ä¸ºå‡è¡¡ã€‚è¯¥æ•°æ®é›†æ˜¯ä¸ºè§†è§‰æŒ‡ä»¤è°ƒæ•´ä¸­çš„ç‰¹å¾å¯¹é½é¢„è®­ç»ƒé˜¶æ®µè€Œæ„å»ºçš„ã€‚ç›®æ ‡æ˜¯å»ºç«‹é¢å‘ GPT-4 è§†è§‰/è¯­è¨€èƒ½åŠ›çš„å¤§å‹å¤šæ¨¡æ€ã€‚ |
| 2 | LLaVA-Instruct-150K | Instruct | EN| [ğŸ¤—](https://huggingface.co/datasets/liuhaotian/LLaVA-Instruct-150K) / [ğŸ¤–](https://www.modelscope.cn/datasets/thomas/LLaVA-Instruct-150K/files) | [haotian-liu](https://github.com/haotian-liu) | [HomePage](https://llava-vl.github.io) / [Paper](https://arxiv.org/abs/2310.03744) / [GitHub](https://github.com/haotian-liu/LLaVA) | LLaVA Visual Instruct 150K æ˜¯ä¸€å¥—ç”± GPT ç”Ÿæˆçš„å¤šæ¨¡æ€æŒ‡ä»¤è·Ÿè¸ªæ•°æ®ã€‚å®ƒæ˜¯ä¸ºè§†è§‰æŒ‡ä»¤è°ƒæ•´å’Œå»ºç«‹é¢å‘ GPT-4 è§†è§‰/è¯­è¨€èƒ½åŠ›çš„å¤§å‹å¤šæ¨¡æ€è€Œæ„å»ºçš„ã€‚ |
| 3 | ShareGPT4V | PreTrain & Instruct | EN | [ğŸ¤—](https://huggingface.co/datasets/Lin-Chen/ShareGPT4V) / [ğŸ¤–](https://www.modelscope.cn/datasets/thomas/ShareGPT4V/summary) | [LinChen](https://github.com/xiaoachen98) | [HomePage](https://sharegpt4v.github.io) / [paper](https://arxiv.org/abs/2311.12793) / [GitHub](https://github.com/InternLM/InternLM-XComposer/tree/main/projects/ShareGPT4V) | ShareGPT4V Captions 1.2M æ˜¯ä¸€ç»„ç”± GPT4-Vision æ”¯æŒçš„å¤šæ¨¡æ€å­—å¹•æ•°æ®ã€‚å…¶æ„å»ºç›®çš„æ˜¯ä¸ºäº†åœ¨é¢„è®­ç»ƒå’Œç›‘ç£å¾®è°ƒé˜¶æ®µå¢å¼ºå¤§å‹å¤šæ¨¡æ€æ¨¡å‹ï¼ˆLMMï¼‰çš„æ¨¡æ€å¯¹é½å’Œç»†ç²’åº¦è§†è§‰æ¦‚å¿µæ„ŸçŸ¥èƒ½åŠ›ã€‚è¿™ä¸€è¿›æ­¥æ—¨åœ¨ä½¿ LMM è¾¾åˆ° GPT4-Vision çš„èƒ½åŠ›ã€‚ |
| 4 | ViP-LLaVA-Instruct | Instruct | EN | [ğŸ¤—](https://huggingface.co/datasets/mucai/ViP-LLaVA-Instruct) / [ğŸ¤–](https://www.modelscope.cn/datasets/thomas/ViP-LLaVA-Instruct/summary) | [mu-cai](https://github.com/mu-cai) | [HomePage](https://vip-llava.github.io) / [Paper](https://arxiv.org/abs/2312.00784) / [GitHub](https://github.com/WisconsinAIVision/ViP-LLaVA) | ViP-LLaVA Instructç”±LLaVA-1.5æŒ‡ä»¤æ•°æ®å’ŒåŒºåŸŸçº§è§†è§‰æç¤ºæ•°æ®ç»„æˆã€‚å®ƒçš„æ„é€ ç”¨äºè§†è§‰æŒ‡ä»¤è°ƒä¼˜å’Œæ„å»ºå¤§å‹å¤šå¼è”è¿ï¼Œä»¥å®ç°GPT-4çº§åŒºåŸŸç†è§£èƒ½åŠ›ã€‚ |
| 5 | MoE-LLaVA | EN | PreTrain & Instruct | [ğŸ¤—](https://huggingface.co/datasets/LanguageBind/MoE-LLaVA) / [ğŸ¤–](https://www.modelscope.cn/datasets/thomas/MoE-LLaVA/summary) | [LanguageBind](https://github.com/LinB203) | [Paper](https://arxiv.org/abs/2401.15947) / [GitHub](https://github.com/PKU-YuanGroup/MoE-LLaVA) | / |
| 6 | AS-V2 | EN | PreTrain & Instruct | [ğŸ¤—](https://huggingface.co/datasets/OpenGVLab/AS-V2) / [ğŸ¤–](https://www.modelscope.cn/datasets/thomas/AS-V2/summary) | [OpenGVLab](https://github.com/OpenGVLab) | [Paper](https://arxiv.org/abs/2402.19474) / [GitHub](https://github.com/OpenGVLab/all-seeing) | æå‡ºäº†ä¸€é¡¹æ–°ä»»åŠ¡ï¼Œç§°ä¸º "å…³ç³»å¯¹è¯ï¼ˆReCï¼‰"ï¼Œå®ƒå°†æ–‡æœ¬ç”Ÿæˆã€å¯¹è±¡å®šä½å’Œå…³ç³»ç†è§£ç»Ÿä¸€èµ·æ¥ã€‚åœ¨ç»Ÿä¸€è¡¨è¿°çš„åŸºç¡€ä¸Šï¼Œæˆ‘ä»¬æ„å»ºäº†ç”± 127K ä¸ªé«˜è´¨é‡å…³ç³»å¯¹è¯æ ·æœ¬ç»„æˆçš„ AS-V2 æ•°æ®é›†ï¼Œä»¥é‡Šæ”¾å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰çš„ ReC èƒ½åŠ›ã€‚ |
| 7 | llava-plus-data | EN | Instruct | [ğŸ¤—](https://huggingface.co/datasets/LLaVA-VL/llava-plus-data) / [ğŸ¤–](https://www.modelscope.cn/datasets/thomas/llava-plus-data/summary) | [LLaVA-VL](https://github.com/LLaVA-VL) | [HomePage](https://llava-vl.github.io/llava-plus/) / [Paper](https://arxiv.org/abs/2311.05437) / [GitHub](https://github.com/LLaVA-VL/LLaVA-Plus-Codebase) | LLaVA-Plus-v1-117K æ˜¯ä¸€å¥—ç”± GPT ç”Ÿæˆçš„å¤šæ¨¡æ€å·¥å…·å¢å¼ºæŒ‡ä»¤è·Ÿéšæ•°æ®ã€‚å®ƒæ˜¯ä¸ºæ„å»ºå…·æœ‰ GPT-4-plus è§†è§‰/è¯­è¨€èƒ½åŠ›çš„å¤šæ¨¡æ€å¤§æ¨¡å‹è€Œæ„å»ºçš„ï¼Œäº2023å¹´9æœˆé€šè¿‡æç¤ºChatGPT/GPT-4-0314 APIæ”¶é›†ã€‚ |
| 8 | ALLaVA-4V | EN | PreTrain & Instruct | [ğŸ¤—](https://huggingface.co/datasets/FreedomIntelligence/ALLaVA-4V) / [ğŸ¤–](https://www.modelscope.cn/datasets/thomas/ALLaVA-4V/summary) | [FreedomIntelligence](https://github.com/FreedomIntelligence) | [Paper](https://arxiv.org/abs/2402.11684) / [GitHub](https://github.com/FreedomIntelligence/ALLaVA) | / |
| 9 | ALLaVA-4V-Chinses | CN | PreTrain & Instruct | [ğŸ¤—](https://huggingface.co/datasets/FreedomIntelligence/ALLaVA-4V-Chinese) / [ğŸ¤–](https://www.modelscope.cn/datasets/thomas/ALLaVA-4V-Chinese/summary) | [FreedomIntelligence](https://github.com/FreedomIntelligence) | [Paper](https://arxiv.org/abs/2402.11684) / [GitHub](https://github.com/FreedomIntelligence/ALLaVA) | / |
| 10 | the_cauldron | EN | PreTrain & Instruct | [ğŸ¤—](https://huggingface.co/datasets/HuggingFaceM4/the_cauldron) / [ğŸ¤–](https://www.modelscope.cn/datasets/thomas/the_cauldron/summary) | [HuggingFaceM4](https://huggingface.co/HuggingFaceM4) | / | è¿™æ˜¯50ä¸ªè§†è§‰è¯­è¨€æ•°æ®é›†ï¼ˆä»…é™è®­ç»ƒé›†ï¼‰çš„å¤§é‡é›†åˆï¼Œç”¨äºå¾®è°ƒè§†è§‰è¯­è¨€æ¨¡å‹Idefics2ã€‚ |
| 11 | UniMM-Chat | EN | Instruct | [ğŸ¤—](https://huggingface.co/datasets/Yirany/UniMM-Chat) / [ğŸ¤–](https://www.modelscope.cn/datasets/thomas/UniMM-Chat/summary) | [thunlp](https://github.com/thunlp) | [Paper](https://arxiv.org/abs/2310.00653) / [GitHub](https://github.com/thunlp/muffin) | UniMM-Chatæ•°æ®é›†æ˜¯ç”±GPT-3.5æä¾›æ”¯æŒçš„å¼€æºã€çŸ¥è¯†å¯†é›†å‹å’Œå¤šè½®å¤šæ¨¡å¼å¯¹è¯æ•°æ®ï¼Œåˆ©ç”¨æ¥è‡ªä¸åŒVLæ•°æ®é›†çš„è¡¥å……æ³¨é‡Šï¼Œå¹¶ä½¿ç”¨GPT-3.5ç”Ÿæˆä¸æ¯ä¸ªå›¾åƒå¯¹åº”çš„å¤šè½®å¯¹è¯ï¼Œäº§ç”Ÿ117,238ä¸ªå¯¹è¯ï¼Œå¹³å‡æ¯ä¸ªå¯¹è¯9.89ä¸ªå›åˆã€‚ |
| 12 | SA1B-Dense-Caption | Pretrain | CN | [ğŸ¤–](https://www.modelscope.cn/datasets/Tongyi-DataEngine/SA1B-Dense-Caption/summary) | [Tongyi-DataEngine](https://www.modelscope.cn/organization/Tongyi-DataEngine) | / | sa-1bæ•°æ®é›†ä¸­çš„8631528å¼ å›¾ç‰‡çš„è¯¦ç»†çš„ã€é«˜è´¨é‡çš„ã€é•¿æ–‡æœ¬æè¿°ã€‚è¯¥æ•°æ®é›†çš„å›¾ç‰‡æè¿°åˆ†ä¸ºæ•´ä½“æè¿°å’Œç»†èŠ‚å…ƒç´ ä¸¤æ–¹é¢ï¼Œå…¶ä¸­ç»†èŠ‚æè¿°ä¸ºå›¾ç‰‡ä¸­çš„é‡ç‚¹å…ƒç´ çš„æè¿°ï¼Œæ•´ä½“ è¿°åŒ…å«ç»†èŠ‚æè¿°æ±‡æ€»å„ç§ä¿¡æ¯ |
| 13 | Layout-Instruction-Data | Pretrain & Instruct | EN |  [ğŸ¤–](https://www.modelscope.cn/datasets/iic/Layout-Instruction-Data/summary) | [AlibabaResearch](https://github.com/AlibabaResearch) |  [Paper](https://arxiv.org/abs/2404.05225) / [GitHub](https://github.com/AlibabaResearch/AdvancedLiterateMachinery/tree/783504f985b100267e9ecab42cabfddd3b026a4f/DocumentUnderstanding/LayoutLLM) | å¸ƒå±€æŒ‡ä»¤è°ƒä¼˜æ•°æ® |
| 14 | DocReason25K | Instruct | EN | [ğŸ¤—](https://huggingface.co/datasets/mPLUG/DocReason25K) / [ğŸ¤–](https://www.modelscope.cn/datasets/iic/DocReason25K/summary) | [X-PLUG](https://github.com/X-PLUG) | [Paper](https://arxiv.org/abs/2403.12895) / [GitHub](https://github.com/X-PLUG/mPLUG-DocOwl) | DocReason25Kæ˜¯mPLUG-DocOwl1.5-Chatä½¿ç”¨çš„æ–‡æ¡£é¢†åŸŸå¸¦æœ‰è¯¦ç»†æ¨ç†è§£é‡Šçš„æŒ‡ä»¤å¾®è°ƒè®­ç»ƒé›†ã€‚ DocReason25Kä¸­çš„é—®é¢˜æ¥æºäºDocVQA, InfographicsVQA, WikiTableQuestions, VisualMRC, ChartQAä»¥åŠTextVQAã€‚ DocReason25Kä¸­çš„è¯¦ç»†æ¨ç†è§£é‡Šç”±GPT3.5æˆ–GPT4Väº§ç”Ÿï¼Œå¹¶é€šè¿‡å’Œäººå·¥æ ‡æ³¨çš„ç®€å•å›å¤è¿›è¡Œå¯¹æ¯”æ¥è¿‡æ»¤é”™è¯¯çš„ç­”æ¡ˆã€‚ |
| 15 | DocStruct4M | Pretrain & Instruct | EN | [ğŸ¤—](https://huggingface.co/datasets/mPLUG/DocStruct4M) / [ğŸ¤–](https://www.modelscope.cn/datasets/iic/DocStruct4M/summary) | [X-PLUG](https://github.com/X-PLUG) | [Paper](https://arxiv.org/abs/2403.12895) / [GitHub](https://github.com/X-PLUG/mPLUG-DocOwl) | DocStruct4Mæ˜¯å¤šæ¨¡æ€æ–‡æ¡£å¤§æ¨¡å‹mPLUG-DocOwl1.5åœ¨â€œç»Ÿä¸€æ–‡æ¡£ç»“æ„å­¦ä¹ â€é˜¶æ®µçš„è®­ç»ƒé›†ï¼Œè¦†ç›–æ–‡æ¡£å›¾ç‰‡ã€ç½‘é¡µå›¾ç‰‡ã€è¡¨æ ¼ã€å›¾è¡¨å’Œè‡ªç„¶å›¾ã€‚ å®ƒåŒ…å«å¤§æ¦‚3M"ç»“æ„åŒ–è§£æ"è®­ç»ƒæ ·ä¾‹ä»¥åŠ1M"å¤šç²’åº¦æ–‡å­—å®šä½å’Œè¯†åˆ«"æ ·ä¾‹ã€‚ |
| 16 | DocDownstream | Pretrain & Instruct  | EN | [ğŸ¤—](https://huggingface.co/datasets/mPLUG/DocDownstream-1.0) / [ğŸ¤–](https://www.modelscope.cn/datasets/iic/DocDownstream-1.0/summary) | [X-PLUG](https://github.com/X-PLUG) | [Paper](https://arxiv.org/abs/2403.12895) / [GitHub](https://github.com/X-PLUG/mPLUG-DocOwl) | DocDownstream-1.0æ•´åˆäº†10ä¸ªæ–‡æ¡£å›¾ç‰‡ç†è§£æ•°æ®é›†ï¼ŒåŒ…æ‹¬DocVQA, InfographicsVQA, DeepForm, KleisterCharity, WikiTableQuestions, TabFact, ChartQA, TextCaps, TextVQAä»¥åŠVisualMRCã€‚ ä»»åŠ¡åŒ…æ‹¬ä¿¡æ¯æŠ½å–ã€è§†è§‰é—®ç­”ã€è‡ªç„¶è¯­è¨€æ¨ç†ä»¥åŠå›¾ç‰‡æè¿°ç­‰ã€‚DocDownstream-1.0å°†æ‰€æœ‰ä»»åŠ¡ç»Ÿä¸€ä¸ºé—®ç­”çš„å½¢å¼ã€‚ |
| 17 | DocLocal4K | Pretrain & Instruct | EN | [ğŸ¤—](https://huggingface.co/datasets/mPLUG/DocLocal4K) / [ğŸ¤–](https://www.modelscope.cn/datasets/iic/DocLocal4K/summary) | [X-PLUG](https://github.com/X-PLUG) | [Paper](https://arxiv.org/abs/2403.12895) / [GitHub](https://github.com/X-PLUG/mPLUG-DocOwl) | / |


## ç›¸å…³é¡¹ç›®

## Benchmark

## æ¨ç†æ¡†æ¶